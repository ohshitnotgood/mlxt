{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model quantisation\n",
    "\n",
    "#### Objective: Quantise Mistral 7B to run off a Nvidia 4070 Super\n",
    "\n",
    "- Used \"bits and bytes\" to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/praanto/.miniforge3/envs/mlxt/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.11s/it]\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Write me an essay about Transformers as a metaphor for the development of technology\n",
      "\n",
      "Transformers, a popular franchise of toy robots co-created by Hasbro and Takara Tomy, has grown beyond its original purpose as a simple toy into a global cultural phenomenon spreading across various art forms, including movies, literature, and television. These mechanical beings, which can change from one form to another, allow us to ponder upon the metaphysical concept of the nature of change. However, Transformers also serve as an effective metaphor for the development of technology.\n",
      "\n",
      "When we examine the evolution of Transformers through the decades, we can observe parallels with the progression of technology. The original Transformers, which debuted in the late seventies, were simple, mechanical toys requiring manual dexterity and human interaction to transform. They reflected the state of technology during that era, where humans were the primary drivers of innovation, and machines were simple tools designed to serve their needs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\", quantization_config=quantization_config, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "\n",
    "prompt = \"Write me an essay about Transformers\"\n",
    "\n",
    "model_inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "generated_ids = model.generate(**model_inputs, max_new_tokens=200, do_sample=True)\n",
    "\n",
    "print(tokenizer.batch_decode(generated_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlxt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
